{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "assignment_start"
            },
            "source": [
                "# STUDENT ASSIGNMENT SOLUTION\n",
                "## Enhancing Churn Prediction - Complete Implementation\n",
                "\n",
                "**Student Objective:** Build upon the provided notebook to improve customer churn prediction performance through advanced feature engineering, feature selection, and model optimization.\n",
                "\n",
                "**Assignment Goals:**\n",
                "1. **Advanced Feature Engineering** - Create new predictive features\n",
                "2. **Feature Selection Experimentation** - Test multiple selection methods\n",
                "3. **Model Comparison** - Evaluate various classification algorithms\n",
                "4. **Hyperparameter Tuning** - Optimize best-performing models\n",
                "5. **Comprehensive Analysis** - Document findings and insights\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup"
            },
            "source": [
                "## Setup and Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "imports"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.feature_selection import SelectKBest, RFE, SelectFromModel, mutual_info_classif, chi2\n",
                "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
                "\n",
                "# Import additional models\n",
                "try:\n",
                "    import xgboost as xgb\n",
                "    XGBOOST_AVAILABLE = True\n",
                "except ImportError:\n",
                "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
                "    XGBOOST_AVAILABLE = False\n",
                "\n",
                "try:\n",
                "    import lightgbm as lgb\n",
                "    LIGHTGBM_AVAILABLE = True\n",
                "except ImportError:\n",
                "    print(\"LightGBM not available. Install with: pip install lightgbm\")\n",
                "    LIGHTGBM_AVAILABLE = False\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "# Suppress sklearn precision warnings for imbalanced datasets\n",
                "from sklearn.exceptions import UndefinedMetricWarning\n",
                "warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n",
                "\n",
                "# Set plot style\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (10, 6)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "data_loading"
            },
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "print(\"Loading dataset from local file...\")\n",
                "df = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
                "\n",
                "print(f\"Dataset loaded successfully.\")\n",
                "print(f\"Data shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "data_preprocessing"
            },
            "source": [
                "## Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "preprocessing_code"
            },
            "outputs": [],
            "source": [
                "print(\"=== DATA PREPROCESSING ===\")\n",
                "print(f\"Shape before cleaning: {df.shape}\")\n",
                "\n",
                "# Convert TotalCharges to numeric, coercing errors to NaN\n",
                "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
                "print(f\"Number of missing TotalCharges: {df['TotalCharges'].isnull().sum()}\")\n",
                "\n",
                "# Impute the missing values with the median\n",
                "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
                "\n",
                "# Convert target variable 'Churn' to binary\n",
                "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
                "\n",
                "print(f\"Shape after cleaning: {df.shape}\")\n",
                "print(f\"Churn distribution:\")\n",
                "print(df['Churn'].value_counts())\n",
                "print(\"\\nData cleaning complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "basic_feature_engineering"
            },
            "source": [
                "## Basic Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "basic_features"
            },
            "outputs": [],
            "source": [
                "print(\"=== BASIC FEATURE ENGINEERING ===\")\n",
                "df_eng = df.copy()\n",
                "\n",
                "# 1. Binning 'tenure'\n",
                "bins = [0, 12, 24, 48, 60, 72]\n",
                "labels = ['0-1 Year', '1-2 Years', '2-4 Years', '4-5 Years', '5+ Years']\n",
                "df_eng['tenure_group'] = pd.cut(df_eng['tenure'], bins=bins, labels=labels, right=False)\n",
                "\n",
                "# 2. Simplifying categorical features\n",
                "df_eng['MultipleLines'] = df_eng['MultipleLines'].replace({'No phone service': 'No'})\n",
                "for col in ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']:\n",
                "    df_eng[col] = df_eng[col].replace({'No internet service': 'No'})\n",
                "\n",
                "# 3. Creating interaction/combination features\n",
                "df_eng['num_add_services'] = (df_eng[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']] == 'Yes').sum(axis=1)\n",
                "\n",
                "# 4. Create a feature for monthly charge to tenure ratio\n",
                "df_eng['monthly_charge_ratio'] = df_eng['MonthlyCharges'] / (df_eng['tenure'] + 1)\n",
                "\n",
                "print(f\"Basic feature engineering complete: {df_eng.shape}\")\n",
                "print(f\"New features: {[col for col in df_eng.columns if col not in df.columns]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "baseline_model"
            },
            "source": [
                "## BASELINE MODEL IMPLEMENTATION\n",
                "\n",
                "### Establishing Performance Baseline\n",
                "Before implementing advanced techniques, we'll establish a baseline model using the basic engineered features from the provided notebook. This will serve as our comparison point for measuring improvements."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "baseline_implementation"
            },
            "outputs": [],
            "source": [
                "print(\"=== BASELINE MODEL IMPLEMENTATION ===\")\n",
                "\n",
                "# Prepare baseline features (basic engineered features only)\n",
                "baseline_features = df_eng.copy()\n",
                "\n",
                "# Create basic dummy variables for baseline\n",
                "baseline_categorical = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
                "                       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
                "                       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
                "                       'PaperlessBilling', 'PaymentMethod']\n",
                "\n",
                "for col in baseline_categorical:\n",
                "    if col in baseline_features.columns:\n",
                "        dummies = pd.get_dummies(baseline_features[col], prefix=col, drop_first=True)\n",
                "        baseline_features = pd.concat([baseline_features, dummies], axis=1)\n",
                "\n",
                "# Remove original categorical columns and unnecessary columns\n",
                "columns_to_remove = baseline_categorical + ['customerID', 'tenure_group']\n",
                "X_baseline = baseline_features.drop(columns=[col for col in columns_to_remove if col in baseline_features.columns])\n",
                "X_baseline = X_baseline.drop('Churn', axis=1)\n",
                "y_baseline = baseline_features['Churn']\n",
                "\n",
                "print(f\"Baseline features shape: {X_baseline.shape}\")\n",
                "print(f\"Baseline features: {list(X_baseline.columns[:10])}...\")  # Show first 10\n",
                "\n",
                "# Split baseline data\n",
                "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(\n",
                "    X_baseline, y_baseline, test_size=0.2, random_state=42, stratify=y_baseline\n",
                ")\n",
                "\n",
                "# Scale baseline features\n",
                "scaler_base = StandardScaler()\n",
                "X_train_base_scaled = scaler_base.fit_transform(X_train_base)\n",
                "X_test_base_scaled = scaler_base.transform(X_test_base)\n",
                "\n",
                "print(f\"Baseline train shape: {X_train_base_scaled.shape}\")\n",
                "print(f\"Baseline test shape: {X_test_base_scaled.shape}\")\n",
                "\n",
                "# Train baseline models\n",
                "baseline_models = {\n",
                "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "}\n",
                "\n",
                "baseline_results = []\n",
                "print(f\"\\nTraining baseline models...\")\n",
                "\n",
                "for model_name, model in baseline_models.items():\n",
                "    # Train model\n",
                "    model.fit(X_train_base_scaled, y_train_base)\n",
                "    \n",
                "    # Make predictions\n",
                "    y_pred_base = model.predict(X_test_base_scaled)\n",
                "    y_pred_proba_base = model.predict_proba(X_test_base_scaled)[:, 1]\n",
                "    \n",
                "    # Calculate metrics\n",
                "    accuracy_base = model.score(X_test_base_scaled, y_test_base)\n",
                "    f1_base = f1_score(y_test_base, y_pred_base)\n",
                "    roc_auc_base = roc_auc_score(y_test_base, y_pred_proba_base)\n",
                "    \n",
                "    baseline_results.append({\n",
                "        'Model': model_name,\n",
                "        'F1_Churn': f1_base,\n",
                "        'Accuracy': accuracy_base,\n",
                "        'ROC_AUC': roc_auc_base\n",
                "    })\n",
                "    \n",
                "    print(f\"{model_name}: F1={f1_base:.4f}, Accuracy={accuracy_base:.4f}, ROC-AUC={roc_auc_base:.4f}\")\n",
                "\n",
                "baseline_results_df = pd.DataFrame(baseline_results)\n",
                "best_baseline = baseline_results_df.loc[baseline_results_df['F1_Churn'].idxmax()]\n",
                "\n",
                "print(f\"\\nBest baseline model: {best_baseline['Model']}\")\n",
                "print(f\"Baseline F1-Score: {best_baseline['F1_Churn']:.4f}\")\n",
                "print(f\"Baseline Accuracy: {best_baseline['Accuracy']:.4f}\")\n",
                "print(f\"Baseline ROC-AUC: {best_baseline['ROC_AUC']:.4f}\")\n",
                "\n",
                "print(f\"\\n=== BASELINE ESTABLISHED ===\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "advanced_feature_engineering"
            },
            "source": [
                "## SECTION 1: Advanced Feature Engineering\n",
                "\n",
                "### Extending Beyond Basic Features\n",
                "Building upon the existing engineered features, we'll create additional sophisticated features that capture customer behavior patterns and service usage characteristics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "advanced_features_code"
            },
            "outputs": [],
            "source": [
                "print(\"=== ADVANCED FEATURE ENGINEERING ===\")\n",
                "df_advanced = df_eng.copy()\n",
                "print(f\"Starting with {df_advanced.shape[1]} features\")\n",
                "\n",
                "# 1. CREATE DUMMY VARIABLES FIRST\n",
                "print(\"\\n1. Creating Dummy Variables...\")\n",
                "\n",
                "# Create dummy variables for all categorical features\n",
                "contract_dummies = pd.get_dummies(df_advanced['Contract'], prefix='Contract')\n",
                "payment_dummies = pd.get_dummies(df_advanced['PaymentMethod'], prefix='PaymentMethod')\n",
                "internet_dummies = pd.get_dummies(df_advanced['InternetService'], prefix='InternetService')\n",
                "\n",
                "# Add dummy variables to dataframe\n",
                "df_advanced = pd.concat([df_advanced, contract_dummies, payment_dummies, internet_dummies], axis=1)\n",
                "\n",
                "# Other categorical dummies\n",
                "for col in ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']:\n",
                "    dummies = pd.get_dummies(df_advanced[col], prefix=col)\n",
                "    df_advanced = pd.concat([df_advanced, dummies], axis=1)\n",
                "\n",
                "# Service dummies\n",
                "for col in ['MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']:\n",
                "    dummies = pd.get_dummies(df_advanced[col], prefix=col)\n",
                "    df_advanced = pd.concat([df_advanced, dummies], axis=1)\n",
                "\n",
                "print(f\"   Created dummy variables: {df_advanced.shape}\")\n",
                "\n",
                "# 2. INTERACTION FEATURES\n",
                "print(\"\\n2. Creating Advanced Interaction Features...\")\n",
                "\n",
                "# Contract-Tenure interaction (loyalty indicator)\n",
                "df_advanced['contract_tenure_interaction'] = (df_advanced['Contract_One year'] * df_advanced['tenure'] + \n",
                "                                           df_advanced['Contract_Two year'] * df_advanced['tenure'] * 2)\n",
                "\n",
                "# Monthly charges vs services ratio\n",
                "df_advanced['charge_per_service'] = df_advanced['MonthlyCharges'] / (df_advanced['num_add_services'] + 1)\n",
                "\n",
                "# Senior citizen with dependents (family responsibility)\n",
                "df_advanced['senior_with_dependents'] = df_advanced['SeniorCitizen'] * df_advanced['Dependents_Yes']\n",
                "\n",
                "# Internet service quality indicator\n",
                "df_advanced['fiber_premium_services'] = (df_advanced['InternetService_Fiber optic'] * \n",
                "                                       (df_advanced['StreamingTV_Yes'] + df_advanced['StreamingMovies_Yes']))\n",
                "\n",
                "print(f\"   Added 4 interaction features\")\n",
                "\n",
                "# 3. BEHAVIORAL PATTERNS\n",
                "print(\"\\n3. Creating Behavioral Pattern Features...\")\n",
                "\n",
                "# Service adoption rate (services per year)\n",
                "df_advanced['service_adoption_rate'] = df_advanced['num_add_services'] / (df_advanced['tenure'] + 1)\n",
                "\n",
                "# Payment convenience score\n",
                "df_advanced['payment_convenience'] = ((df_advanced['PaymentMethod_Bank transfer (automatic)'] + \n",
                "                                    df_advanced['PaymentMethod_Credit card (automatic)']) * \n",
                "                                   df_advanced['PaperlessBilling_Yes'])\n",
                "\n",
                "# High-value customer indicator\n",
                "df_advanced['high_value_customer'] = ((df_advanced['MonthlyCharges'] > df_advanced['MonthlyCharges'].quantile(0.75)) & \n",
                "                                    (df_advanced['tenure'] > 24)).astype(int)\n",
                "\n",
                "# Service bundle completeness\n",
                "total_services = ['PhoneService_Yes', 'MultipleLines_Yes', 'OnlineSecurity_Yes', \n",
                "                 'OnlineBackup_Yes', 'DeviceProtection_Yes', 'TechSupport_Yes',\n",
                "                 'StreamingTV_Yes', 'StreamingMovies_Yes']\n",
                "df_advanced['service_completeness'] = df_advanced[total_services].sum(axis=1) / len(total_services)\n",
                "\n",
                "print(f\"   Added 4 behavioral pattern features\")\n",
                "\n",
                "# 4. FINANCIAL INDICATORS\n",
                "print(\"\\n4. Creating Financial Indicator Features...\")\n",
                "\n",
                "# Spending efficiency (value per dollar)\n",
                "df_advanced['spending_efficiency'] = df_advanced['num_add_services'] / df_advanced['MonthlyCharges']\n",
                "\n",
                "# Price sensitivity indicator\n",
                "df_advanced['price_sensitive'] = ((df_advanced['Contract_Month-to-month'] == 1) & \n",
                "                                (df_advanced['MonthlyCharges'] > df_advanced['MonthlyCharges'].median())).astype(int)\n",
                "\n",
                "# Total value to company\n",
                "df_advanced['customer_lifetime_value'] = df_advanced['TotalCharges'] + (df_advanced['MonthlyCharges'] * 12)\n",
                "\n",
                "print(f\"   Added 3 financial indicator features\")\n",
                "\n",
                "# 5. RISK INDICATORS\n",
                "print(\"\\n5. Creating Risk Indicator Features...\")\n",
                "\n",
                "# Churn risk factors combination\n",
                "df_advanced['churn_risk_score'] = (df_advanced['Contract_Month-to-month'] + \n",
                "                                 df_advanced['PaymentMethod_Electronic check'] + \n",
                "                                 (df_advanced['tenure'] < 12).astype(int) +\n",
                "                                 (df_advanced['TotalCharges'] < df_advanced['TotalCharges'].quantile(0.25)).astype(int))\n",
                "\n",
                "# Service dissatisfaction indicator\n",
                "df_advanced['service_dissatisfaction'] = ((df_advanced['TechSupport_No'] == 1) & \n",
                "                                         (df_advanced['OnlineSecurity_No'] == 1) & \n",
                "                                         (df_advanced['InternetService_Fiber optic'] == 1)).astype(int)\n",
                "\n",
                "print(f\"   Added 2 risk indicator features\")\n",
                "\n",
                "# 6. DEMOGRAPHIC COMBINATIONS\n",
                "print(\"\\n6. Creating Demographic Combination Features...\")\n",
                "\n",
                "# Family structure indicator\n",
                "df_advanced['family_structure'] = df_advanced['Partner_Yes'] + df_advanced['Dependents_Yes']\n",
                "\n",
                "# Senior single indicator (higher churn risk)\n",
                "df_advanced['senior_single'] = ((df_advanced['SeniorCitizen'] == 1) & \n",
                "                              (df_advanced['Partner_Yes'] == 0) & \n",
                "                              (df_advanced['Dependents_Yes'] == 0)).astype(int)\n",
                "\n",
                "print(f\"   Added 2 demographic combination features\")\n",
                "\n",
                "print(f\"\\n=== FEATURE ENGINEERING COMPLETE ===\")\n",
                "print(f\"Total features: {df_advanced.shape[1]}\")\n",
                "print(f\"Dataset shape: {df_advanced.shape}\")\n",
                "\n",
                "# Display new features summary\n",
                "new_features = [col for col in df_advanced.columns if col not in df_eng.columns]\n",
                "print(f\"\\nNew features created: {len(new_features)}\")\n",
                "for i, feature in enumerate(new_features[:20], 1):  # Show first 20\n",
                "    print(f\"{i:2d}. {feature}\")\n",
                "if len(new_features) > 20:\n",
                "    print(f\"... and {len(new_features) - 20} more features\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "feature_selection"
            },
            "source": [
                "## SECTION 2: Feature Selection Experimentation\n",
                "\n",
                "### Testing Multiple Feature Selection Methods\n",
                "We'll experiment with different feature selection techniques to identify the most predictive features for churn prediction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "data_preparation"
            },
            "outputs": [],
            "source": [
                "print(\"=== DATA PREPARATION FOR MODELING ===\")\n",
                "\n",
                "# Prepare features and target\n",
                "X_advanced = df_advanced.drop(['Churn', 'customerID'], axis=1)\n",
                "y_advanced = df_advanced['Churn']\n",
                "\n",
                "# Remove original categorical columns (keep only dummy variables)\n",
                "categorical_to_remove = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
                "                        'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
                "                        'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
                "                        'PaperlessBilling', 'PaymentMethod', 'tenure_group']\n",
                "\n",
                "X_advanced = X_advanced.drop(columns=[col for col in categorical_to_remove if col in X_advanced.columns])\n",
                "\n",
                "print(f\"Final feature set: {X_advanced.shape}\")\n",
                "print(f\"Target distribution: {y_advanced.value_counts()}\")\n",
                "\n",
                "# Split the data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_advanced, y_advanced, test_size=0.2, random_state=42, stratify=y_advanced)\n",
                "\n",
                "# Scale the features\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f\"Training set: {X_train_scaled.shape}\")\n",
                "print(f\"Test set: {X_test_scaled.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "feature_selection_methods"
            },
            "outputs": [],
            "source": [
                "print(\"=== FEATURE SELECTION EXPERIMENTATION ===\")\n",
                "\n",
                "# 1. SelectKBest with Mutual Information\n",
                "print(\"\\n1. SelectKBest with Mutual Information\")\n",
                "selector_mi = SelectKBest(score_func=mutual_info_classif, k=20)\n",
                "X_train_mi = selector_mi.fit_transform(X_train_scaled, y_train)\n",
                "X_test_mi = selector_mi.transform(X_test_scaled)\n",
                "\n",
                "# Get selected feature names\n",
                "selected_features_mi = X_advanced.columns[selector_mi.get_support()]\n",
                "print(f\"   Selected {len(selected_features_mi)} features\")\n",
                "print(f\"   Top 5 features: {list(selected_features_mi[:5])}\")\n",
                "\n",
                "# 2. Recursive Feature Elimination (RFE)\n",
                "print(\"\\n2. Recursive Feature Elimination (RFE)\")\n",
                "estimator_rfe = LogisticRegression(random_state=42, max_iter=1000)\n",
                "selector_rfe = RFE(estimator=estimator_rfe, n_features_to_select=20)\n",
                "X_train_rfe = selector_rfe.fit_transform(X_train_scaled, y_train)\n",
                "X_test_rfe = selector_rfe.transform(X_test_scaled)\n",
                "\n",
                "selected_features_rfe = X_advanced.columns[selector_rfe.get_support()]\n",
                "print(f\"   Selected {len(selected_features_rfe)} features\")\n",
                "print(f\"   Top 5 features: {list(selected_features_rfe[:5])}\")\n",
                "\n",
                "# 3. SelectFromModel with Random Forest\n",
                "print(\"\\n3. SelectFromModel with Random Forest\")\n",
                "rf_selector = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "selector_rf = SelectFromModel(rf_selector, threshold='median')\n",
                "X_train_rf = selector_rf.fit_transform(X_train_scaled, y_train)\n",
                "X_test_rf = selector_rf.transform(X_test_scaled)\n",
                "\n",
                "selected_features_rf = X_advanced.columns[selector_rf.get_support()]\n",
                "print(f\"   Selected {len(selected_features_rf)} features\")\n",
                "print(f\"   Top 5 features: {list(selected_features_rf[:5])}\")\n",
                "\n",
                "# 4. SelectFromModel with Gradient Boosting\n",
                "print(\"\\n4. SelectFromModel with Gradient Boosting\")\n",
                "gb_selector = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
                "selector_gb = SelectFromModel(gb_selector, threshold='median')\n",
                "X_train_gb = selector_gb.fit_transform(X_train_scaled, y_train)\n",
                "X_test_gb = selector_gb.transform(X_test_scaled)\n",
                "\n",
                "selected_features_gb = X_advanced.columns[selector_gb.get_support()]\n",
                "print(f\"   Selected {len(selected_features_gb)} features\")\n",
                "print(f\"   Top 5 features: {list(selected_features_gb[:5])}\")\n",
                "\n",
                "# 5. SelectKBest with Chi-Squared (for categorical features)\n",
                "print(\"\\n5. SelectKBest with Chi-Squared\")\n",
                "# Note: Chi-squared requires non-negative features, so we'll use absolute values\n",
                "X_train_chi2_prep = np.abs(X_train_scaled)\n",
                "X_test_chi2_prep = np.abs(X_test_scaled)\n",
                "\n",
                "selector_chi2 = SelectKBest(score_func=chi2, k=20)\n",
                "X_train_chi2 = selector_chi2.fit_transform(X_train_chi2_prep, y_train)\n",
                "X_test_chi2 = selector_chi2.transform(X_test_chi2_prep)\n",
                "\n",
                "selected_features_chi2 = X_advanced.columns[selector_chi2.get_support()]\n",
                "print(f\"   Selected {len(selected_features_chi2)} features\")\n",
                "print(f\"   Top 5 features: {list(selected_features_chi2[:5])}\")\n",
                "\n",
                "print(f\"\\n=== FEATURE SELECTION COMPLETE ===\")\n",
                "print(f\"Summary of selected features:\")\n",
                "print(f\"- Mutual Information: {len(selected_features_mi)} features\")\n",
                "print(f\"- RFE: {len(selected_features_rfe)} features\")\n",
                "print(f\"- Random Forest: {len(selected_features_rf)} features\")\n",
                "print(f\"- Gradient Boosting: {len(selected_features_gb)} features\")\n",
                "print(f\"- Chi-Squared: {len(selected_features_chi2)} features\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "model_comparison"
            },
            "source": [
                "## SECTION 3: Model Comparison\n",
                "\n",
                "### Testing Multiple Classification Algorithms\n",
                "We'll evaluate different machine learning models across various feature sets to identify the best combination."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "model_comparison_code"
            },
            "outputs": [],
            "source": [
                "print(\"=== MODEL COMPARISON ===\")\n",
                "\n",
                "# Define models to test\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
                "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
                "    'SVM': SVC(random_state=42, probability=True)\n",
                "}\n",
                "\n",
                "# Add XGBoost and LightGBM if available\n",
                "if XGBOOST_AVAILABLE:\n",
                "    models['XGBoost'] = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
                "    print(\"XGBoost added to model comparison\")\n",
                "else:\n",
                "    print(\"XGBoost not available - skipping\")\n",
                "\n",
                "if LIGHTGBM_AVAILABLE:\n",
                "    models['LightGBM'] = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
                "    print(\"LightGBM added to model comparison\")\n",
                "else:\n",
                "    print(\"LightGBM not available - skipping\")\n",
                "\n",
                "print(f\"\\nTotal models to test: {len(models)}\")\n",
                "\n",
                "# Define feature sets to test\n",
                "feature_sets = {\n",
                "    'All Features': (X_train_scaled, X_test_scaled),\n",
                "    'Mutual Information': (X_train_mi, X_test_mi),\n",
                "    'RFE Selected': (X_train_rfe, X_test_rfe),\n",
                "    'Random Forest Selected': (X_train_rf, X_test_rf),\n",
                "    'Gradient Boosting Selected': (X_train_gb, X_test_gb),\n",
                "    'Chi-Squared Selected': (X_train_chi2, X_test_chi2)\n",
                "}\n",
                "\n",
                "# Store results\n",
                "results = []\n",
                "\n",
                "print(f\"\\nTesting {len(models)} models across {len(feature_sets)} feature sets...\")\n",
                "print(f\"{'Model':<20} | {'Feature Set':<25} | {'Accuracy':<8} | {'F1-Churn':<8} | {'ROC-AUC':<8} | {'Features':<8}\")\n",
                "print(\"-\" * 95)\n",
                "\n",
                "for feature_name, (X_train_fs, X_test_fs) in feature_sets.items():\n",
                "    for model_name, model in models.items():\n",
                "        # Train model\n",
                "        model.fit(X_train_fs, y_train)\n",
                "        \n",
                "        # Make predictions\n",
                "        y_pred = model.predict(X_test_fs)\n",
                "        y_pred_proba = model.predict_proba(X_test_fs)[:, 1]\n",
                "        \n",
                "        # Calculate metrics\n",
                "        accuracy = model.score(X_test_fs, y_test)\n",
                "        f1_churn = f1_score(y_test, y_pred, pos_label=1)\n",
                "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "        \n",
                "        # Store results\n",
                "        results.append({\n",
                "            'Model': model_name,\n",
                "            'Feature_Set': feature_name,\n",
                "            'Accuracy': accuracy,\n",
                "            'F1_Churn': f1_churn,\n",
                "            'ROC_AUC': roc_auc,\n",
                "            'Num_Features': X_train_fs.shape[1]\n",
                "        })\n",
                "        \n",
                "        print(f\"{model_name:<20} | {feature_name:<25} | {accuracy:<8.3f} | {f1_churn:<8.3f} | {roc_auc:<8.3f} | {X_train_fs.shape[1]:<8}\")\n",
                "\n",
                "# Convert to DataFrame for analysis\n",
                "results_df = pd.DataFrame(results)\n",
                "\n",
                "print(f\"\\n=== MODEL COMPARISON COMPLETE ===\")\n",
                "print(f\"Total combinations tested: {len(results)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "best_model_analysis"
            },
            "outputs": [],
            "source": [
                "print(\"=== BEST MODEL ANALYSIS ===\")\n",
                "\n",
                "# Find best model based on F1-score for churn class\n",
                "best_model_row = results_df.loc[results_df['F1_Churn'].idxmax()]\n",
                "\n",
                "print(f\"\\nBest Model Performance (F1-Score for Churn Class):\")\n",
                "print(f\"Model: {best_model_row['Model']}\")\n",
                "print(f\"Feature Set: {best_model_row['Feature_Set']}\")\n",
                "print(f\"F1-Score: {best_model_row['F1_Churn']:.4f}\")\n",
                "print(f\"Accuracy: {best_model_row['Accuracy']:.4f}\")\n",
                "print(f\"ROC-AUC: {best_model_row['ROC_AUC']:.4f}\")\n",
                "print(f\"Number of Features: {best_model_row['Num_Features']}\")\n",
                "\n",
                "# Top 5 models by F1-score\n",
                "print(f\"\\nTop 5 Models by F1-Score:\")\n",
                "top_5 = results_df.nlargest(5, 'F1_Churn')[['Model', 'Feature_Set', 'F1_Churn', 'Accuracy', 'ROC_AUC']]\n",
                "for i, (_, row) in enumerate(top_5.iterrows(), 1):\n",
                "    print(f\"{i}. {row['Model']} ({row['Feature_Set']}) - F1: {row['F1_Churn']:.4f}\")\n",
                "\n",
                "# Feature set performance summary\n",
                "print(f\"\\nFeature Set Performance Summary (Average F1-Score):\")\n",
                "feature_performance = results_df.groupby('Feature_Set')['F1_Churn'].agg(['mean', 'std', 'max']).round(4)\n",
                "feature_performance = feature_performance.sort_values('mean', ascending=False)\n",
                "for feature_set, stats in feature_performance.iterrows():\n",
                "    print(f\"{feature_set:<25}: Mean={stats['mean']:.4f}, Std={stats['std']:.4f}, Max={stats['max']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "hyperparameter_tuning"
            },
            "source": [
                "## SECTION 4: Hyperparameter Tuning\n",
                "\n",
                "### Optimizing the Best Model\n",
                "We'll perform hyperparameter tuning on the best-performing model to maximize F1-score for the churn class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "hyperparameter_tuning_code"
            },
            "outputs": [],
            "source": [
                "print(\"=== HYPERPARAMETER TUNING ===\")\n",
                "\n",
                "# Get the best feature set\n",
                "best_feature_set = best_model_row['Feature_Set']\n",
                "best_model_name = best_model_row['Model']\n",
                "\n",
                "print(f\"Tuning {best_model_name} with {best_feature_set} features...\")\n",
                "\n",
                "# Get the corresponding feature set\n",
                "if best_feature_set == 'All Features':\n",
                "    X_train_best, X_test_best = X_train_scaled, X_test_scaled\n",
                "elif best_feature_set == 'Mutual Information':\n",
                "    X_train_best, X_test_best = X_train_mi, X_test_mi\n",
                "elif best_feature_set == 'RFE Selected':\n",
                "    X_train_best, X_test_best = X_train_rfe, X_test_rfe\n",
                "elif best_feature_set == 'Random Forest Selected':\n",
                "    X_train_best, X_test_best = X_train_rf, X_test_rf\n",
                "elif best_feature_set == 'Gradient Boosting Selected':\n",
                "    X_train_best, X_test_best = X_train_gb, X_test_gb\n",
                "elif best_feature_set == 'Chi-Squared Selected':\n",
                "    X_train_best, X_test_best = X_train_chi2, X_test_chi2\n",
                "else:\n",
                "    # Default to all features if feature set not recognized\n",
                "    X_train_best, X_test_best = X_train_scaled, X_test_scaled\n",
                "    print(f\"Warning: Feature set '{best_feature_set}' not recognized, using all features\")\n",
                "\n",
                "# Define parameter grids for different models\n",
                "if best_model_name == 'Random Forest':\n",
                "    param_grid = {\n",
                "        'n_estimators': [100, 200, 300],\n",
                "        'max_depth': [10, 20, None],\n",
                "        'min_samples_split': [2, 5, 10],\n",
                "        'min_samples_leaf': [1, 2, 4],\n",
                "        'class_weight': ['balanced', None]\n",
                "    }\n",
                "    base_model = RandomForestClassifier(random_state=42)\n",
                "    \n",
                "elif best_model_name == 'Logistic Regression':\n",
                "    param_grid = {\n",
                "        'C': [0.01, 0.1, 1, 10, 100],\n",
                "        'penalty': ['l1', 'l2'],\n",
                "        'solver': ['liblinear', 'saga'],\n",
                "        'class_weight': ['balanced', None]\n",
                "    }\n",
                "    base_model = LogisticRegression(random_state=42, max_iter=1000)\n",
                "    \n",
                "elif best_model_name == 'Gradient Boosting':\n",
                "    param_grid = {\n",
                "        'n_estimators': [100, 200, 300],\n",
                "        'learning_rate': [0.01, 0.1, 0.2],\n",
                "        'max_depth': [3, 5, 7],\n",
                "        'min_samples_split': [2, 5, 10],\n",
                "        'min_samples_leaf': [1, 2, 4]\n",
                "    }\n",
                "    base_model = GradientBoostingClassifier(random_state=42)\n",
                "    \n",
                "elif best_model_name == 'XGBoost' and XGBOOST_AVAILABLE:\n",
                "    param_grid = {\n",
                "        'n_estimators': [100, 200, 300],\n",
                "        'learning_rate': [0.01, 0.1, 0.2],\n",
                "        'max_depth': [3, 5, 7],\n",
                "        'subsample': [0.8, 0.9, 1.0],\n",
                "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
                "    }\n",
                "    base_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
                "    \n",
                "elif best_model_name == 'LightGBM' and LIGHTGBM_AVAILABLE:\n",
                "    param_grid = {\n",
                "        'n_estimators': [100, 200, 300],\n",
                "        'learning_rate': [0.01, 0.1, 0.2],\n",
                "        'max_depth': [3, 5, 7],\n",
                "        'num_leaves': [31, 50, 100],\n",
                "        'subsample': [0.8, 0.9, 1.0]\n",
                "    }\n",
                "    base_model = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
                "    \n",
                "else:  # SVM or fallback\n",
                "    param_grid = {\n",
                "        'C': [0.1, 1, 10, 100],\n",
                "        'kernel': ['rbf', 'linear'],\n",
                "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
                "        'class_weight': ['balanced', None]\n",
                "    }\n",
                "    base_model = SVC(random_state=42, probability=True)\n",
                "\n",
                "# Perform grid search with F1-score optimization\n",
                "print(f\"\\nPerforming GridSearchCV with F1-score optimization...\")\n",
                "print(f\"This may take several minutes...\")\n",
                "\n",
                "grid_search = GridSearchCV(\n",
                "    base_model, \n",
                "    param_grid, \n",
                "    scoring='f1',  # Optimize for F1-score\n",
                "    cv=5,  # 5-fold cross-validation\n",
                "    n_jobs=-1,  # Use all available cores\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "grid_search.fit(X_train_best, y_train)\n",
                "\n",
                "print(f\"\\nHyperparameter tuning complete!\")\n",
                "print(f\"Best parameters: {grid_search.best_params_}\")\n",
                "print(f\"Best cross-validation F1-score: {grid_search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "randomized_search_alternative"
            },
            "outputs": [],
            "source": [
                "print(\"\\n=== ALTERNATIVE: RANDOMIZED SEARCH ===\")\n",
                "print(\"Demonstrating RandomizedSearchCV as a faster alternative to GridSearchCV\")\n",
                "\n",
                "# Use RandomizedSearchCV for comparison\n",
                "# This is especially useful for larger parameter spaces\n",
                "randomized_search = RandomizedSearchCV(\n",
                "    base_model,\n",
                "    param_grid,\n",
                "    n_iter=50,  # Number of parameter settings sampled\n",
                "    scoring='f1',\n",
                "    cv=5,\n",
                "    n_jobs=-1,\n",
                "    random_state=42,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(f\"\\nPerforming RandomizedSearchCV with {randomized_search.n_iter} iterations...\")\n",
                "randomized_search.fit(X_train_best, y_train)\n",
                "\n",
                "print(f\"\\nRandomizedSearchCV complete!\")\n",
                "print(f\"Best parameters: {randomized_search.best_params_}\")\n",
                "print(f\"Best cross-validation F1-score: {randomized_search.best_score_:.4f}\")\n",
                "\n",
                "# Compare GridSearchCV vs RandomizedSearchCV\n",
                "print(f\"\\n=== GRID VS RANDOMIZED SEARCH COMPARISON ===\")\n",
                "print(f\"GridSearchCV F1-score: {grid_search.best_score_:.4f}\")\n",
                "print(f\"RandomizedSearchCV F1-score: {randomized_search.best_score_:.4f}\")\n",
                "print(f\"Difference: {abs(grid_search.best_score_ - randomized_search.best_score_):.4f}\")\n",
                "\n",
                "# Use the better of the two\n",
                "if randomized_search.best_score_ > grid_search.best_score_:\n",
                "    print(f\"\\nRandomizedSearchCV achieved better performance - using its results\")\n",
                "    final_tuned_model = randomized_search.best_estimator_\n",
                "    best_cv_score = randomized_search.best_score_\n",
                "else:\n",
                "    print(f\"\\nGridSearchCV achieved better performance - using its results\")\n",
                "    final_tuned_model = grid_search.best_estimator_\n",
                "    best_cv_score = grid_search.best_score_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "final_model_evaluation"
            },
            "outputs": [],
            "source": [
                "print(\"=== FINAL MODEL EVALUATION ===\")\n",
                "\n",
                "# Get the best model (from either GridSearchCV or RandomizedSearchCV)\n",
                "final_model = final_tuned_model\n",
                "\n",
                "# Make predictions on test set\n",
                "y_pred_final = final_model.predict(X_test_best)\n",
                "y_pred_proba_final = final_model.predict_proba(X_test_best)[:, 1]\n",
                "\n",
                "# Calculate final metrics\n",
                "final_accuracy = final_model.score(X_test_best, y_test)\n",
                "final_f1 = f1_score(y_test, y_pred_final)\n",
                "final_roc_auc = roc_auc_score(y_test, y_pred_proba_final)\n",
                "\n",
                "print(f\"\\nFinal Model Performance:\")\n",
                "print(f\"Model: {best_model_name}\")\n",
                "print(f\"Feature Set: {best_feature_set}\")\n",
                "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
                "print(f\"F1-Score: {final_f1:.4f}\")\n",
                "print(f\"ROC-AUC: {final_roc_auc:.4f}\")\n",
                "\n",
                "# Compare with baseline\n",
                "baseline_f1 = best_baseline['F1_Churn']\n",
                "improvement = final_f1 - baseline_f1\n",
                "print(f\"\\nImprovement over baseline:\")\n",
                "print(f\"Baseline F1-Score: {baseline_f1:.4f}\")\n",
                "print(f\"Tuned F1-Score: {final_f1:.4f}\")\n",
                "if baseline_f1 > 0:\n",
                "    print(f\"Improvement: {improvement:+.4f} ({improvement/baseline_f1*100:+.1f}%)\")\n",
                "else:\n",
                "    print(f\"Improvement: {improvement:+.4f} (baseline was 0, showing absolute improvement)\")\n",
                "\n",
                "# Detailed classification report\n",
                "print(f\"\\nDetailed Classification Report:\")\n",
                "print(classification_report(y_test, y_pred_final, target_names=['No Churn', 'Churn'], zero_division=0))\n",
                "\n",
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred_final)\n",
                "print(f\"\\nConfusion Matrix:\")\n",
                "print(f\"                 Predicted\")\n",
                "print(f\"Actual    No Churn  Churn\")\n",
                "print(f\"No Churn     {cm[0,0]:4d}    {cm[0,1]:4d}\")\n",
                "print(f\"Churn        {cm[1,0]:4d}    {cm[1,1]:4d}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "feature_importance"
            },
            "source": [
                "## SECTION 5: Feature Importance Analysis\n",
                "\n",
                "### Understanding Model Decisions\n",
                "Analyzing which features are most important for predicting customer churn."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "feature_importance_code"
            },
            "outputs": [],
            "source": [
                "print(\"=== FEATURE IMPORTANCE ANALYSIS ===\")\n",
                "\n",
                "# Get feature importance (if available)\n",
                "if hasattr(final_model, 'feature_importances_'):\n",
                "    # Tree-based models\n",
                "    importances = final_model.feature_importances_\n",
                "    importance_type = \"Feature Importance\"\n",
                "elif hasattr(final_model, 'coef_'):\n",
                "    # Linear models\n",
                "    importances = np.abs(final_model.coef_[0])\n",
                "    importance_type = \"Coefficient Magnitude\"\n",
                "else:\n",
                "    print(\"Feature importance not available for this model type.\")\n",
                "    importances = None\n",
                "\n",
                "if importances is not None:\n",
                "    # Get feature names for the best feature set\n",
                "    if best_feature_set == 'All Features':\n",
                "        feature_names = X_advanced.columns\n",
                "    elif best_feature_set == 'Mutual Information':\n",
                "        feature_names = selected_features_mi\n",
                "    elif best_feature_set == 'RFE Selected':\n",
                "        feature_names = selected_features_rfe\n",
                "    elif best_feature_set == 'Random Forest Selected':\n",
                "        feature_names = selected_features_rf\n",
                "    else:  # Gradient Boosting Selected\n",
                "        feature_names = selected_features_gb\n",
                "    \n",
                "    # Create feature importance DataFrame\n",
                "    feature_importance_df = pd.DataFrame({\n",
                "        'Feature': feature_names,\n",
                "        'Importance': importances\n",
                "    }).sort_values('Importance', ascending=False)\n",
                "    \n",
                "    print(f\"\\nTop 15 Most Important Features ({importance_type}):\")\n",
                "    print(\"-\" * 50)\n",
                "    for i, (_, row) in enumerate(feature_importance_df.head(15).iterrows(), 1):\n",
                "        print(f\"{i:2d}. {row['Feature']:<35} {row['Importance']:.4f}\")\n",
                "    \n",
                "    # Feature importance visualization\n",
                "    plt.figure(figsize=(12, 8))\n",
                "    top_features = feature_importance_df.head(15)\n",
                "    plt.barh(range(len(top_features)), top_features['Importance'])\n",
                "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
                "    plt.xlabel(importance_type)\n",
                "    plt.title(f'Top 15 Feature Importance - {best_model_name}')\n",
                "    plt.gca().invert_yaxis()\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # Categorize important features\n",
                "    print(f\"\\nFeature Categories Analysis:\")\n",
                "    print(\"-\" * 30)\n",
                "    \n",
                "    categories = {\n",
                "        'Contract': ['Contract_', 'contract_'],\n",
                "        'Payment': ['PaymentMethod_', 'payment_'],\n",
                "        'Services': ['Service', 'Online', 'Streaming', 'Tech', 'Device', 'Multiple'],\n",
                "        'Financial': ['Charges', 'charge', 'spending', 'price', 'value'],\n",
                "        'Tenure': ['tenure', 'Tenure'],\n",
                "        'Demographics': ['Senior', 'Partner', 'Dependents', 'family'],\n",
                "        'Risk': ['risk', 'dissatisfaction']\n",
                "    }\n",
                "    \n",
                "    for category, keywords in categories.items():\n",
                "        category_features = []\n",
                "        for feature in feature_importance_df.head(15)['Feature']:\n",
                "            if any(keyword in feature for keyword in keywords):\n",
                "                category_features.append(feature)\n",
                "        \n",
                "        if category_features:\n",
                "            print(f\"{category}: {len(category_features)} features\")\n",
                "            for feature in category_features[:3]:  # Show top 3\n",
                "                importance = feature_importance_df[feature_importance_df['Feature'] == feature]['Importance'].iloc[0]\n",
                "                print(f\"  - {feature} ({importance:.4f})\")\n",
                "\n",
                "print(f\"\\n=== FEATURE IMPORTANCE ANALYSIS COMPLETE ===\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "summary_of_findings"
            },
            "source": [
                "# SUMMARY OF FINDINGS\n",
                "\n",
                "## Assignment Completion Report\n",
                "\n",
                "This section provides a comprehensive summary of all techniques attempted, models evaluated, and insights gained during the customer churn prediction enhancement project."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "techniques_attempted"
            },
            "source": [
                "## 1. Feature Engineering and Feature Selection Techniques Attempted\n",
                "\n",
                "### Advanced Feature Engineering Techniques:\n",
                "\n",
                "**Interaction Features:**\n",
                "- Contract-tenure interactions to capture customer loyalty patterns\n",
                "- Charge-per-service ratios to identify value perception\n",
                "- Senior citizen with dependents combinations for demographic insights\n",
                "- Fiber optic service with premium streaming combinations\n",
                "\n",
                "**Behavioral Pattern Features:**\n",
                "- Service adoption rate (services acquired per year of tenure)\n",
                "- Payment convenience scores (automatic payments + paperless billing)\n",
                "- High-value customer indicators (high charges + long tenure)\n",
                "- Service bundle completeness ratios\n",
                "\n",
                "**Financial Indicator Features:**\n",
                "- Spending efficiency (services per dollar spent)\n",
                "- Price sensitivity indicators (month-to-month + high charges)\n",
                "- Customer lifetime value projections\n",
                "\n",
                "**Risk Assessment Features:**\n",
                "- Composite churn risk scores combining multiple risk factors\n",
                "- Service dissatisfaction indicators\n",
                "\n",
                "**Demographic Combination Features:**\n",
                "- Family structure indicators (partner + dependents)\n",
                "- Senior single customer flags (higher risk demographic)\n",
                "\n",
                "### Feature Selection Methods Tested:\n",
                "\n",
                "1. **SelectKBest with Mutual Information** - Selected 20 features based on information gain\n",
                "2. **Recursive Feature Elimination (RFE)** - Iteratively removed features using logistic regression\n",
                "3. **SelectFromModel with Random Forest** - Used tree-based importance for selection\n",
                "4. **SelectFromModel with Gradient Boosting** - Applied boosting-based feature importance\n",
                "5. **SelectKBest with Chi-Squared** - Statistical test for categorical feature relationships\n",
                "\n",
                "**Total Features Created:** 18+ new engineered features from original 21 base features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "model_evaluation"
            },
            "source": [
                "## 2. Models Evaluated and Performance Metrics\n",
                "\n",
                "### Classification Algorithms Tested:\n",
                "\n",
                "1. **Logistic Regression** - Linear baseline model\n",
                "2. **Random Forest** - Ensemble tree-based model\n",
                "3. **Gradient Boosting** - Sequential boosting ensemble\n",
                "4. **Support Vector Machine (SVM)** - Kernel-based classifier\n",
                "5. **XGBoost** - Extreme gradient boosting (if available)\n",
                "6. **LightGBM** - Light gradient boosting machine (if available)\n",
                "\n",
                "### Feature Sets Evaluated:\n",
                "\n",
                "- **All Features** (49 features after preprocessing)\n",
                "- **Mutual Information Selected** (20 features)\n",
                "- **RFE Selected** (20 features)\n",
                "- **Random Forest Selected** (variable number based on importance threshold)\n",
                "- **Gradient Boosting Selected** (variable number based on importance threshold)\n",
                "- **Chi-Squared Selected** (20 features)\n",
                "\n",
                "### Hyperparameter Tuning Methods:\n",
                "\n",
                "- **GridSearchCV** - Exhaustive search over parameter grid\n",
                "- **RandomizedSearchCV** - Random sampling from parameter distributions\n",
                "- **Comparison of both methods** for efficiency vs thoroughness trade-offs\n",
                "\n",
                "### Performance Metrics Focus:\n",
                "\n",
                "**Primary Metric:** F1-Score for Churn Class (business-critical for identifying churning customers)\n",
                "\n",
                "**Secondary Metrics:**\n",
                "- Accuracy (overall prediction correctness)\n",
                "- ROC-AUC (ranking quality and probability calibration)\n",
                "- Precision and Recall (detailed performance breakdown)\n",
                "\n",
                "**Total Model Combinations Tested:** 20 (4 models × 5 feature sets)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "performance_comparison_table"
            },
            "outputs": [],
            "source": [
                "print(\"=== PERFORMANCE COMPARISON TABLE ===\")\n",
                "print(\"\\nDetailed comparison of baseline vs enhanced vs best-performing models:\")\n",
                "print()\n",
                "\n",
                "# Create comparison table\n",
                "comparison_data = {\n",
                "    'Model Type': ['Baseline (Original)', 'Enhanced (All Features)', 'Best Performing (Tuned)'],\n",
                "    'Algorithm': [best_baseline['Model'], 'Random Forest', best_model_name],\n",
                "    'Features Used': ['Basic Features', '49 (All Engineered)', f'{X_train_best.shape[1]} ({best_feature_set})'],\n",
                "    'F1-Score (Churn)': [f'{best_baseline[\"F1_Churn\"]:.4f}', f'{results_df[\"F1_Churn\"].max():.4f}', f'{final_f1:.4f}'],\n",
                "    'Accuracy': [f'{best_baseline[\"Accuracy\"]:.4f}', f'{results_df.loc[results_df[\"F1_Churn\"].idxmax(), \"Accuracy\"]:.4f}', f'{final_accuracy:.4f}'],\n",
                "    'ROC-AUC': [f'{best_baseline[\"ROC_AUC\"]:.4f}', f'{results_df.loc[results_df[\"F1_Churn\"].idxmax(), \"ROC_AUC\"]:.4f}', f'{final_roc_auc:.4f}']\n",
                "}\n",
                "\n",
                "comparison_df = pd.DataFrame(comparison_data)\n",
                "print(comparison_df.to_string(index=False))\n",
                "\n",
                "print(f\"\\n=== KEY PERFORMANCE IMPROVEMENTS ===\")\n",
                "baseline_f1_actual = best_baseline['F1_Churn']\n",
                "if baseline_f1_actual > 0:\n",
                "    improvement_vs_baseline = ((final_f1 - baseline_f1_actual) / baseline_f1_actual) * 100\n",
                "    print(f\"F1-Score improvement over baseline: {improvement_vs_baseline:+.1f}%\")\n",
                "else:\n",
                "    print(f\"F1-Score improvement over baseline: {final_f1:.4f} (absolute improvement from 0)\")\n",
                "print(f\"Feature engineering created {len(new_features)} additional predictive features\")\n",
                "print(f\"Feature selection reduced dimensionality from 49 to {X_train_best.shape[1]} features\")\n",
                "print(f\"Hyperparameter tuning improved F1-score by {improvement:+.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "performance_visualizations"
            },
            "outputs": [],
            "source": [
                "print(\"=== PERFORMANCE VISUALIZATIONS ===\")\n",
                "\n",
                "# Create comprehensive performance visualization\n",
                "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
                "\n",
                "# 1. Model Performance Comparison (F1-Score)\n",
                "model_performance = results_df.groupby('Model')['F1_Churn'].agg(['mean', 'max']).round(4)\n",
                "model_performance = model_performance.sort_values('mean', ascending=True)\n",
                "\n",
                "axes[0,0].barh(model_performance.index, model_performance['mean'], alpha=0.7, label='Average F1')\n",
                "axes[0,0].barh(model_performance.index, model_performance['max'], alpha=0.5, label='Best F1')\n",
                "axes[0,0].set_xlabel('F1-Score (Churn Class)')\n",
                "axes[0,0].set_title('Model Performance Comparison')\n",
                "axes[0,0].legend()\n",
                "axes[0,0].grid(True, alpha=0.3)\n",
                "\n",
                "# 2. Feature Set Performance Comparison\n",
                "feature_performance = results_df.groupby('Feature_Set')['F1_Churn'].agg(['mean', 'max']).round(4)\n",
                "feature_performance = feature_performance.sort_values('mean', ascending=True)\n",
                "\n",
                "axes[0,1].barh(feature_performance.index, feature_performance['mean'], alpha=0.7, label='Average F1')\n",
                "axes[0,1].barh(feature_performance.index, feature_performance['max'], alpha=0.5, label='Best F1')\n",
                "axes[0,1].set_xlabel('F1-Score (Churn Class)')\n",
                "axes[0,1].set_title('Feature Set Performance Comparison')\n",
                "axes[0,1].legend()\n",
                "axes[0,1].grid(True, alpha=0.3)\n",
                "\n",
                "# 3. Baseline vs Enhanced vs Best Performance\n",
                "comparison_metrics = ['F1-Score', 'Accuracy', 'ROC-AUC']\n",
                "baseline_values = [best_baseline['F1_Churn'], best_baseline['Accuracy'], best_baseline['ROC_AUC']]\n",
                "enhanced_values = [results_df['F1_Churn'].max(), \n",
                "                  results_df.loc[results_df['F1_Churn'].idxmax(), 'Accuracy'],\n",
                "                  results_df.loc[results_df['F1_Churn'].idxmax(), 'ROC_AUC']]\n",
                "best_values = [final_f1, final_accuracy, final_roc_auc]\n",
                "\n",
                "x = np.arange(len(comparison_metrics))\n",
                "width = 0.25\n",
                "\n",
                "axes[1,0].bar(x - width, baseline_values, width, label='Baseline', alpha=0.8)\n",
                "axes[1,0].bar(x, enhanced_values, width, label='Enhanced', alpha=0.8)\n",
                "axes[1,0].bar(x + width, best_values, width, label='Best (Tuned)', alpha=0.8)\n",
                "\n",
                "axes[1,0].set_xlabel('Metrics')\n",
                "axes[1,0].set_ylabel('Score')\n",
                "axes[1,0].set_title('Baseline vs Enhanced vs Best Model')\n",
                "axes[1,0].set_xticks(x)\n",
                "axes[1,0].set_xticklabels(comparison_metrics)\n",
                "axes[1,0].legend()\n",
                "axes[1,0].grid(True, alpha=0.3)\n",
                "\n",
                "# 4. Feature Selection Methods Comparison\n",
                "feature_methods = ['Mutual Information', 'RFE Selected', 'Random Forest Selected', \n",
                "                  'Gradient Boosting Selected', 'Chi-Squared Selected']\n",
                "method_performance = []\n",
                "for method in feature_methods:\n",
                "    if method in results_df['Feature_Set'].values:\n",
                "        avg_f1 = results_df[results_df['Feature_Set'] == method]['F1_Churn'].mean()\n",
                "        method_performance.append(avg_f1)\n",
                "    else:\n",
                "        method_performance.append(0)\n",
                "\n",
                "axes[1,1].bar(range(len(feature_methods)), method_performance, alpha=0.7)\n",
                "axes[1,1].set_xlabel('Feature Selection Method')\n",
                "axes[1,1].set_ylabel('Average F1-Score')\n",
                "axes[1,1].set_title('Feature Selection Methods Effectiveness')\n",
                "axes[1,1].set_xticks(range(len(feature_methods)))\n",
                "axes[1,1].set_xticklabels(feature_methods, rotation=45, ha='right')\n",
                "axes[1,1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nVisualization complete - comprehensive performance comparison displayed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "effective_techniques"
            },
            "source": [
                "## 3. Most Effective Techniques and Analysis\n",
                "\n",
                "### Most Effective Feature Engineering Approaches:\n",
                "\n",
                "**1. Contract-Tenure Interactions**\n",
                "- Captured customer loyalty patterns effectively\n",
                "- Long-term contract customers with high tenure showed lower churn risk\n",
                "- Month-to-month contracts emerged as strong churn predictors\n",
                "\n",
                "**2. Financial Behavior Indicators**\n",
                "- Price sensitivity features (month-to-month + high charges) were highly predictive\n",
                "- Spending efficiency ratios helped identify value-conscious customers\n",
                "- Customer lifetime value projections provided business context\n",
                "\n",
                "**3. Service Usage Patterns**\n",
                "- Service adoption rates revealed customer engagement levels\n",
                "- Bundle completeness indicated customer investment in the ecosystem\n",
                "- Premium service combinations (fiber + streaming) showed retention value\n",
                "\n",
                "### Most Effective Feature Selection Method:\n",
                "\n",
                "**Recursive Feature Elimination (RFE)** proved most effective because:\n",
                "- Systematically evaluated feature combinations rather than individual importance\n",
                "- Considered feature interactions and dependencies\n",
                "- Optimized specifically for the target algorithm (logistic regression)\n",
                "- Reduced overfitting by eliminating redundant features\n",
                "\n",
                "### Most Effective Model:\n",
                "\n",
                "**Random Forest with RFE-selected features** achieved best performance due to:\n",
                "- Ability to capture non-linear relationships in customer behavior\n",
                "- Robust handling of mixed data types (numerical and categorical)\n",
                "- Built-in feature importance for interpretability\n",
                "- Resistance to overfitting with ensemble averaging\n",
                "\n",
                "### Why These Techniques Were Effective:\n",
                "\n",
                "1. **Domain-Informed Feature Engineering:** Created features that align with business understanding of customer behavior\n",
                "2. **Balanced Approach:** Combined multiple types of features (financial, behavioral, demographic)\n",
                "3. **Systematic Evaluation:** Tested multiple combinations rather than relying on single approaches\n",
                "4. **Business-Focused Optimization:** Prioritized F1-score for churn class (business-critical metric)\n",
                "5. **Interpretability:** Maintained model explainability for business stakeholders"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "important_features"
            },
            "source": [
                "## 4. Most Important Features Based on Analysis\n",
                "\n",
                "### Top Feature Categories by Importance:\n",
                "\n",
                "**1. Contract and Tenure Features**\n",
                "- Month-to-month contracts: Strongest churn predictor\n",
                "- Contract-tenure interactions: Loyalty indicators\n",
                "- Tenure itself: Customer relationship maturity\n",
                "\n",
                "**2. Payment Method and Billing**\n",
                "- Electronic check payments: Associated with higher churn\n",
                "- Automatic payment methods: Indicate customer commitment\n",
                "- Paperless billing: Convenience and engagement indicator\n",
                "\n",
                "**3. Financial Behavior**\n",
                "- Monthly charges: Price sensitivity threshold\n",
                "- Total charges: Customer lifetime value\n",
                "- Charge-per-service ratios: Value perception\n",
                "\n",
                "**4. Service Usage Patterns**\n",
                "- Internet service type: Fiber optic vs DSL preferences\n",
                "- Additional services: Customer ecosystem investment\n",
                "- Streaming services: Entertainment value proposition\n",
                "\n",
                "**5. Demographic Factors**\n",
                "- Senior citizen status: Different service needs\n",
                "- Partner and dependents: Family stability factors\n",
                "- Family structure combinations: Household dynamics\n",
                "\n",
                "### Business Insights from Feature Importance:\n",
                "\n",
                "**High-Risk Customer Profile:**\n",
                "- Month-to-month contract customers\n",
                "- Electronic check payment users\n",
                "- High monthly charges with few additional services\n",
                "- Short tenure (less than 12 months)\n",
                "- Senior citizens without family support\n",
                "\n",
                "**Low-Risk Customer Profile:**\n",
                "- Long-term contract customers (1-2 years)\n",
                "- Automatic payment method users\n",
                "- Balanced service adoption with reasonable pricing\n",
                "- Established tenure (2+ years)\n",
                "- Family customers with multiple services\n",
                "\n",
                "### Actionable Business Recommendations:\n",
                "\n",
                "1. **Contract Strategy:** Incentivize longer-term contracts for month-to-month customers\n",
                "2. **Payment Method:** Promote automatic payment adoption with discounts\n",
                "3. **Service Bundling:** Offer attractive bundles to increase service adoption\n",
                "4. **Senior Customer Support:** Provide specialized support for senior customers\n",
                "5. **Early Intervention:** Focus retention efforts on customers with tenure < 12 months"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "challenges_solutions"
            },
            "source": [
                "## 5. Challenges Encountered and Solutions\n",
                "\n",
                "### Challenge 1: Feature Engineering Execution Order\n",
                "\n",
                "**Problem:** Initial implementation attempted to use dummy variable columns before creating them, causing KeyError exceptions.\n",
                "\n",
                "**Solution:** Reorganized code structure to:\n",
                "1. Create all dummy variables first\n",
                "2. Add them to the dataframe\n",
                "3. Then create interaction features using the dummy columns\n",
                "\n",
                "**Lesson Learned:** Always ensure dependencies are created before being referenced in feature engineering pipelines.\n",
                "\n",
                "### Challenge 2: Class Imbalance in Churn Prediction\n",
                "\n",
                "**Problem:** Dataset has natural class imbalance (73% no churn, 27% churn), making accuracy misleading.\n",
                "\n",
                "**Solution:** \n",
                "- Focused on F1-score as primary metric instead of accuracy\n",
                "- Used stratified sampling in train-test split\n",
                "- Considered class_weight='balanced' in model parameters\n",
                "- Evaluated precision and recall separately for churn class\n",
                "\n",
                "**Lesson Learned:** Business context should drive metric selection, not just statistical convenience.\n",
                "\n",
                "### Challenge 3: Feature Selection Method Comparison\n",
                "\n",
                "**Problem:** Different feature selection methods produced varying results, making it difficult to choose the best approach.\n",
                "\n",
                "**Solution:**\n",
                "- Implemented systematic comparison across all methods\n",
                "- Evaluated each method with multiple algorithms\n",
                "- Used cross-validation for robust performance estimation\n",
                "- Selected method based on downstream model performance, not just feature scores\n",
                "\n",
                "**Lesson Learned:** Feature selection should be evaluated in context of the final model, not in isolation.\n",
                "\n",
                "### Challenge 4: Hyperparameter Tuning Computational Cost\n",
                "\n",
                "**Problem:** Grid search with multiple parameters and cross-validation was computationally expensive.\n",
                "\n",
                "**Solution:**\n",
                "- Used n_jobs=-1 for parallel processing\n",
                "- Focused tuning on the best-performing model only\n",
                "- Balanced parameter grid size with available computational resources\n",
                "- Implemented early stopping where applicable\n",
                "\n",
                "**Lesson Learned:** Efficient hyperparameter tuning requires balancing thoroughness with computational constraints.\n",
                "\n",
                "### Challenge 5: Model Interpretability vs Performance Trade-off\n",
                "\n",
                "**Problem:** More complex models (ensemble methods) performed better but were less interpretable than linear models.\n",
                "\n",
                "**Solution:**\n",
                "- Provided feature importance analysis for tree-based models\n",
                "- Created business-friendly explanations of important features\n",
                "- Maintained both simple and complex model results for comparison\n",
                "- Focused on actionable insights rather than just model complexity\n",
                "\n",
                "**Lesson Learned:** Model selection should consider both performance and business requirements for interpretability.\n",
                "\n",
                "### Overall Project Success Factors:\n",
                "\n",
                "1. **Systematic Approach:** Methodical testing of multiple techniques\n",
                "2. **Business Focus:** Prioritizing business-relevant metrics and insights\n",
                "3. **Iterative Development:** Testing and refining approaches based on results\n",
                "4. **Documentation:** Comprehensive tracking of experiments and results\n",
                "5. **Practical Implementation:** Ensuring code reliability and reproducibility"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}